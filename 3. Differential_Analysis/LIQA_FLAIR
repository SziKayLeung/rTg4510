# nanopore differential analysis
module load Miniconda2
source activate sqanti2_py3
cd /gpfs/mrc0/projects/Research_Project-MRC148213/sl693/softwares/pipeline-transcriptome-de
snakemake --use-conda -j 8 all
#SBATCH --error=differential_isoseq_mm10.e
#gffread -w output.fa -g genome.fa genome.gtf
cd /gpfs/mrc0/projects/Research_Project-MRC148213/sl693/reference_2019
gffread -w mm10transcriptome.fa -g mm10.fa gencode.vM22.annotation.gtf

# SQANTI2 for All-Merged 
TOFU=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/All_Merged/TOFU/mm10
KALLISTO=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/Kallisto
SQANTI2=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/All_Merged/SQANTI2
RNASEQ=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/RNASeq/all_filtered/Tg4510_filtered
RNASEQ_MERGED=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/RNASeq/all_filtered/Tg4510_filtered/MERGED

source /gpfs/mrc0/projects/Research_Project-MRC148213/sl693/Scripts/general/Post_IsoSeq/Post_Isoseq3_Functions.sh

TG_SAMPLES=(K24 L22 M20 O24 P22 Q20 S24	T22	K22	L20	M18	O22	P20	Q18	S22	T20	K20	L18	M24	O20	P18	Q24	S20	T18	K18	L24	M22	O18	P24	Q22	S18	T24)
WT_SAMPLES=(K17 L21 M19 K23 P21 Q19 M21 T21 K21 L19 M17 O21 P19 Q17 S21 T19 K19 L17 M23 O19 P17 Q23 S19 T17 O23 L23 Q21 O17 P23 S23 S17 T23)
SAMPLES_NAMES+=( "${TG_SAMPLES[@]}" "${WT_SAMPLES[@]}" )

# run_sqanti2_QC <prefix_sample> <input_tofu_dir> <coverage/genome=mm10_rnqaseq/mm10/hg38_gencode/hg38_chess/ERCC> <input_kallisto_file> <output_dir> <input_rnaseq_dir> 
run_sqanti2_QC All_Merged $TOFU mm10_rnqaseq $KALLISTO/All_RNASeq.mod.abundance.tsv $SQANTI2 $RNASEQ
run_sqanti2_Filter All_Merged $SQANTI2

# merge RNA-Seq R1 and R2 
merge_R1_R2(){

	F_name=$(find $2 -name "*fastq.filtered" -exec basename \{} \; | grep ^$1 | grep "R1" )
	R_name=$(find $2 -name "*fastq.filtered" -exec basename \{} \; | grep ^$1 | grep "R2" )
	# save path directory of files as variable for later mapping
	F_File=$(find $2 -name "$F_name")
	R_File=$(find $2 -name "$R_name")

	echo "Processing Sample $1 for STAR"
	echo "Processing Forward Reads: $F_File"
	echo "Processing Reverse Reads: $R_File"
	
	cat $F_File $R_File > $3/$1"_Merged.fastq.filtered" 
}
IsoSeq_RNASeq
SAMPLES=(K17 L21 M19 K24 L22 M20)
SAMPLES=(O18 K18 S18 L22 Q20 K24 Q21 K17 M21 O23 S23 K23)
for i in ${SAMPLES[@]}; do 
	merge_R1_R2 $i $RNASEQ $RNASEQ_MERGED
done


# LIQA 
LIQA=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/softwares/LIQA
LIQA_OUTPUT=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/Diff_Analysis/LIQA
MAPPING=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Individual/Isoseq3.1.2/MAP
TOFU=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Individual/Isoseq3.1.2/ToFU
CLUSTER=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Individual/Isoseq/Isoseq3_WKD/CLUSTER
git clone https://github.com/WGLab/LIQA.git
# python LIQA.py -task refgene -ref example.refFile -out example.refgene
# conda install -c conda-forge lifelines
# upload reference file generated from UCSC 
cd $LIQA_OUTPUT
gunzip mm10.refFile.gz
python $LIQA/LIQA.py -task refgene -ref mm10.refFile -out mm10.refgene
# python LIQA.py -task quantify -refgene <refgene_file> -bam <bam_file> -out <output_file> -max_distance <max distance>
python $LIQA/LIQA.py -task quantify -refgene mm10.refgene -bam $CLUSTER/K17.polished.bam -out $LIQA_OUTPUT/K17 -max_distance 10 -f_weight 1


# FLAIR
FLAIR_DIR=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/softwares/flair
FLAIR_OUTPUT=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/FLAIR
MAPPING=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Individual/Isoseq/MAPPING
CLUSTER=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Individual/Isoseq/Isoseq3_WKD/CLUSTER
REFERENCE=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/reference_2019

# conda install -c conda-forge tqdm

cd $FLAIR_OUTPUT
for i in $MAPPING/*polished.hq.fastq.sorted.sam*; do
	echo $i
	python $FLAIR_DIR/bin/bam2Bed12.py -i $i > $i.bed12
	head $i.bed12
done

mv $MAPPING/*bed12* $FLAIR_OUTPUT/MAPPING

clustered_reads=(O18.clustered.hq.fasta K18.clustered.hq.fasta S18.clustered.hq.fasta L22.clustered.hq.fasta Q20.clustered.hq.fasta K24.clustered.hq.fasta Q21.clustered.hq.fasta K17.clustered.hq.fasta M21.clustered.hq.fasta O23.clustered.hq.fasta S23.clustered.hq.fasta K23.clustered.hq.fasta)
samples=(O18 K18 S18 L22 Q20 K24 Q21 K17 M21 O23 S23 K23)

for i in {1..11}; do 
	cd $FLAIR_OUTPUT/MAPPING
	echo "Processing $CLUSTER/${clustered_reads[$i]} as output ${samples[$i]}"
	python $FLAIR_DIR/flair.py align -g $REFERENCE/mm10.fa -r $CLUSTER/${clustered_reads[$i]} -o ${samples[$i]}
done
python $FLAIR_DIR/flair.py align -g $REFERENCE/mm10.fa -r $CLUSTER/O18.clustered.hq.fasta -o O18

python $FLAIR_DIR/flair.py align -g $REFERENCE/mm10.fa -r <reads.fq>|<reads.fa> [options]
cat $FLAIR_OUTPUT/MAPPING/*bed12* > All.bed12
python $FLAIR_DIR/flair.py collapse -g $REFERENCE/mm10.fa -r $CLUSTER/O18.clustered.hq.fasta \
	$CLUSTER/K18.clustered.hq.fasta \
	$CLUSTER/S18.clustered.hq.fasta \
	$CLUSTER/L22.clustered.hq.fasta \
	$CLUSTER/Q20.clustered.hq.fasta \
	$CLUSTER/K24.clustered.hq.fasta \
	$CLUSTER/Q21.clustered.hq.fasta \
	$CLUSTER/K17.clustered.hq.fasta \
	$CLUSTER/M21.clustered.hq.fasta \
	$CLUSTER/O23.clustered.hq.fasta \
	$CLUSTER/S23.clustered.hq.fasta \
	$CLUSTER/K23.clustered.hq.fasta -q All.bed12 -f $REFERENCE/gencode.vM22.annotation.gtf

# convert gtf to psl for downstream 
python $FLAIR_DIR/bin/gtf_to_psl.py flair.collapse.isoforms.gtf flair.collapse.isoforms.psl

# kallisto 
KALLISTO=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/Kallisto

run_kallisto(){
    source activate sqanti2
    
    echo "Processing Kallisto for $1"
    cd $4
    kallisto version
    time kallisto index -i $1_Kallisto.idx $2 
    time kallisto quant -i $4/$1_Kallisto.idx --fr-stranded $3/$1_R1.fq --rf-stranded $3/$1_R2.fq -o $4 
    mv abundance.tsv $1".abundance.tsv"
    
    source deactivate
}

run_kallisto All_RNASeq $FLAIR_OUTPUT/flair.collapse.isoforms.fa $KALLISTO $FLAIR_OUTPUT
python $FLAIR_DIR/flair.py quantify -r $FLAIR_OUTPUT/reads_manifest.tsv -i $FLAIR_OUTPUT/flair.collapse.isoforms.fa --tpm
python $FLAIR_DIR/flair.py diffExp -q counts_matrix.tsv.tpm.tsv -o Output_Results
python $FLAIR_DIR/flair.py diffSplice -i flair.collapse.isoforms.psl -q counts_matrix.tsv.tpm.tsv

python $FLAIR_DIR/bin/plot_isoform_usage.py flair.collapse.isoforms.pslcounts_matrix.tsv ENSMUSG00000000276.11
python flair.py diffSplice -i PP_DP_N_tama_sqanti_classification.filtered_lite.bed -q PP_DP_matrix_rename.counts.txt --test -t 20

## Salmon 
DTU=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/Diff_Analysis/DTU
TOFU=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/All_Merged/TOFU/mm10
ALL_MERGED=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/WholeTranscriptome/Tg4510/All_Merged/SQANTI2
# decoys for salmon (https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/)
grep "^>" < $REFERENCE/mm10.fa | cut -d " " -f 1 > decoys.txt
sed -i.bak -e 's/>//g' decoys.txt
cat $TOFU/All_Merged.collapsed.filtered.rep.fa $REFERENCE/mm10.fa > gentrome.fa


salmon index -t gentrome.fa -d decoys.txt -i All_Merged_filtered

K24=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/RNASeq/all_filtered/Tg4510_filtered/K24
S18=/gpfs/mrc0/projects/Research_Project-MRC148213/sl693/RNASeq/all_filtered/Tg4510_filtered/S18
salmon quant -p -16 -t $TOFU/All_Merged.collapsed.filtered.rep.fa -l U --gcBias -o output -1 $K24/K24_S57_R1_001.fastq.filtered $S18/S18_S39_R1_001.fastq.filtered -2 $K24/K24_S57_R2_001.fastq.filtered $S18/S18_S39_R2_001.fastq.filtered


salmon quant --noErrorModel -p {threads} -t {input.trs} -l {params.libtype} -a {input.bam} -o {params.tsv_dir}


